{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from src.helpers import *\n",
    "from src.plot import *\n",
    "pd.options.display.max_rows = 4000\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in Dam and 303d data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '303d_impaired_waters_csv.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-52a17e3a2645>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwaters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'303d_impaired_waters_csv.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ca_dams.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2008\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '303d_impaired_waters_csv.csv'"
     ]
    }
   ],
   "source": [
    "waters = pd.read_csv('303d_impaired_waters_csv.csv')\n",
    "dams = pd.read_csv('ca_dams.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data: Bar graph of all waterbodies and counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_water_bodies(body_list, amount_list, 'Number of Water Body Types', (14, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = fill_nans(waters, 'WATER BODY TYPE', 'Null')\n",
    "# a\n",
    "body_dict = {}\n",
    "waters['WATER BODY TYPE'] = waters['WATER BODY TYPE'].fillna('Null')\n",
    "\n",
    "for body in waters['WATER BODY TYPE']:\n",
    "    if body in body_dict:\n",
    "        body_dict[body] += 1\n",
    "    else:\n",
    "        body_dict[body] = 1\n",
    "\n",
    "body_list = []\n",
    "amount_list = []\n",
    "for k, v in body_dict.items():\n",
    "    body_list.append(k)\n",
    "    amount_list.append(int(v))\n",
    "    \n",
    "# print(body_list, amount_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up dfs a little"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning up 303d data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##csv was from pdf and very messy - drop all rows with NA under Region column\n",
    "#waters=waters.dropna(axis=0, how='all')\n",
    "\n",
    "\n",
    "drop_nans(waters, 0, 'all')\n",
    "\n",
    "##I'm only interested in analyzing river and stream impact - let's filter out all waterbodies that aren't rivers\n",
    "##or streams\n",
    "rivers = waters.loc[waters['WATER BODY TYPE'] == 'River & Stream']\n",
    "#impaired_rivers.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rivers = rivers[['Region', 'Water Body Name', 'POLLUTANT']]\n",
    "rivers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning up dam data - dropping unnecessary columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reduce dataframe\n",
    "\n",
    "dams = dams[['RIVER', 'PRIVATE_DAM']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with NANs in crucial places\n",
    "There are 90 dams that don't have data for River. We will drop these and maybe manually input data later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df[df['EPS'].notna()]\n",
    "dams[dams['RIVER'].isna()].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dams['RIVER'] = dams['RIVER'].str.lower()\n",
    "rivers['Water Body Name'] = rivers['Water Body Name'].str.lower()\n",
    "\n",
    "dams = dams[dams['RIVER'].notna()]\n",
    "dams = dams.loc[dams['RIVER'] != 'offstream']\n",
    "dams = dams.loc[dams['RIVER'] != 'y']\n",
    "dams = dams.loc[dams['RIVER'] != '.']\n",
    "dams = dams.loc[dams['RIVER'] != 3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numeric(df, cols):\n",
    "    for col in cols:\n",
    "        df[col] = df[col].apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_numeric(rivers, ['Region'])\n",
    "rivers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rivers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we'll group the like-rivers together and append all their polutant and possible sources together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_and_condense(rivers, 'Water Body Name', \n",
    "                      'POLLUTANT', 'Water Body Name', 'POLLUTANT')\n",
    "\n",
    "rivers['All Pollutants'] = rivers[[\n",
    "    'Water Body Name',\n",
    "    'Pollutant']].groupby('Water Body Name')['Pollutant'].transform(lambda x: ', '.join(x))\n",
    "\n",
    "#all individual rivers\n",
    "rivers = rivers[['Water Body Name', \n",
    "                 'All Pollutants', \n",
    "                 'Region',]].drop_duplicates()\n",
    "\n",
    "df['Num Pollutants'] = 0\n",
    "for i in range (df['All Pollutants'].count()):\n",
    "    pollutant_list = df['All Pollutants'][i].split(', ')\n",
    "    pollutant_list = list(dict.fromkeys(pollutant_list))\n",
    "    df['All Pollutants'][i] = pollutant_list\n",
    "\n",
    "    df['Num Pollutants'][i] = len(pollutant_list)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now to match up dammed rivers with impaired rivers\n",
    "\n",
    "Our goal is to compile a dataframe with columns:\n",
    "\n",
    "'River', 'Private Dam', 'All Pollutants'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impaired = impaired.set_index('Water Body Name', drop=False)\n",
    "# impaired = impaired.rename(columns={'Water Body Name': 'Merger'})\n",
    "\n",
    "# cal_dams = cal_dams.set_index('RIVER', drop=False)\n",
    "# cal_dams = cal_dams.rename(columns={'RIVER': 'Merger'})\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for impaired_river in impaired['Merger']:\n",
    "    \n",
    "#     for river in cal_dams['Merger']:\n",
    "#         if river in impaired_river:\n",
    "#             impaired['Merger'].loc[impaired['Merger'] == impaired_river] = river\n",
    "#             impaired_river = river\n",
    "#             break\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Condense cal_dams to only one entry per river\n",
    "\n",
    "# s_cal_dams = cal_dams.groupby(['Merger'], sort=False)['PRIVATE_DAM'].apply(lambda x: ','.join(x.astype(str)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging impaired and cal_dams to one df\n",
    "df = all impaired rivers with associated dam values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = impaired.merge(s_cal_dams, how='left', left_on='Merger', right_on='Merger')\n",
    "df = merge_dfs(rivers, dams, 'River', 'River')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOTTING TIME\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bar Chart of #dammed vs. #undammed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dammed = df[df['PRIVATE_DAM'].notnull()]\n",
    "natural = df.loc[df['PRIVATE_DAM'].isnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = [len(df_dammed), len(df_not_dammed)]\n",
    "labels = ['Undammed', 'Dammed']\n",
    "explode = (0, 0.08)\n",
    "\n",
    "fig1, ax1 = plt.subplots(figsize=(5.5,5.5))\n",
    "ax1.pie(num, explode=explode, labels=labels, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "ax1.set_title('Pergentage of Dammed and Undammed Impaired Rivers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a histogram for # of pollutants in dammed and undammed rivers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dammed.index = np.arange(0, len(df_dammed))\n",
    "df_not_dammed.index = np.arange(0, len(df_not_dammed))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "#df_dammed.hist('Num Pollutants', ax=ax, bins=20, bottom=0.1, alpha=.5, color='black')\n",
    "df_not_dammed.hist('Number of Pollutants', ax=ax, bins=20, bottom=0.1, alpha=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "df_dammed.hist('Num Pollutants',ax=ax, bins=20, bottom=0.1, alpha=.5, color='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should plot individual pollutants on the x-axis, and a stacked bar chart on top!\n",
    "\n",
    "1: make a list(maybe dictionary?) of all pollutants\n",
    "\n",
    "2: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A/B Test: Dammed Rivers have more pollutants than non-dammed rivers:\n",
    "ho: Dammed rivers and un_dammed rivers have the same average number of pollutants\n",
    "ha: dammed rivers have more pollutants than undammed rivers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A/B Test:\n",
    "    ho: dammed rivers and undammed rivers have the same distribution of impairments\n",
    "    ha: they have a different distribution of impairments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dammed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_dammed:\n",
    "n = df_dammed['Num Pollutants'].count()   \n",
    "p = sum([x for x in df_dammed['Num Pollutants']])/n\n",
    "p\n",
    "#binomial = stats.binom(n=3100, p=0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_sample_means(data, n_bootstrap_samples=10000):\n",
    "    bootstrap_sample_means = []\n",
    "    for i in range(n_bootstrap_samples):\n",
    "        bootstrap_sample = np.random.choice(data, size=300, replace=True)  ##changed from size=len(data)\n",
    "        bootstrap_sample_means.append(np.mean(bootstrap_sample))\n",
    "    return bootstrap_sample_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dammed_means = bootstrap_sample_means(df_dammed['Num Pollutants'])\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(10, 4))\n",
    "_ = ax.hist(df_dammed['Num Pollutants'], bins=25, density=True, color=\"black\", alpha=0.4,\n",
    "            label=\"Sample Data\")\n",
    "_ = ax.hist(dammed_means, bins=25, density=True, color=\"red\", alpha=0.75,\n",
    "            label=\"Bootstrap Sample Means\")\n",
    "ax.legend()\n",
    "_ = ax.set_title(\"Bootstrap Sample Means Dammed Rivers (10000 samples)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need to normalize based on sample size!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dammed means vs undammed means\n",
    "\n",
    "dammed_means = bootstrap_sample_means(df_dammed['Num Pollutants'])\n",
    "undammed_means = bootstrap_sample_means(df_not_dammed['Num Pollutants'])\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(10, 4))\n",
    "_ = ax.hist(dammed_means, bins=20, density=True, color=\"blue\", alpha=0.4,\n",
    "            label=\"Dammed Rivers\")\n",
    "_ = ax.hist(undammed_means, bins=20, density=True, color=\"red\", alpha=0.75,\n",
    "            label=\"Undammed Rivers\")\n",
    "ax.legend()\n",
    "_ = ax.set_title(\"Mean number of Pollutants in Dammed and Undammed Rivers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot stacked bar graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n = 19\n",
    "# \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = dammed_most_potent.keys()\n",
    "values = dammed_most_potent.values()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,5))\n",
    "plt.bar(keys, values)\n",
    "\n",
    "\n",
    "\n",
    "N = 5\n",
    "menMeans = (20, 35, 30, 35, 27)\n",
    "womenMeans = (25, 32, 34, 20, 25)\n",
    "menStd = (2, 3, 4, 1, 2)\n",
    "womenStd = (3, 5, 2, 3, 3)\n",
    "ind = np.arange(N)    # the x locations for the groups\n",
    "width = 0.35       # the width of the bars: can also be len(x) sequence\n",
    "\n",
    "p1 = plt.bar(ind, menMeans, width, yerr=menStd)\n",
    "p2 = plt.bar(ind, womenMeans, width,\n",
    "             bottom=menMeans, yerr=womenStd)\n",
    "\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Scores by group and gender')\n",
    "plt.xticks(ind, ('G1', 'G2', 'G3', 'G4', 'G5'))\n",
    "plt.yticks(np.arange(0, 81, 10))\n",
    "plt.legend((p1[0], p2[0]), ('Men', 'Women'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dammed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dammed_pollutant_dict = {}\n",
    "for pol in df_dammed['All Pollutants']:\n",
    "    for pollutant in pol:\n",
    "        if pollutant in dammed_pollutant_dict:\n",
    "            dammed_pollutant_dict[pollutant] += 1\n",
    "        else:\n",
    "            dammed_pollutant_dict[pollutant] = 1\n",
    "#for k, v in dammed_pollutant_dict.items():\n",
    "#    print(k, v)\n",
    "dammed_most_potent = {k:v for (k,v) in dammed_pollutant_dict.items() if v > 20}\n",
    "len(dammed_most_potent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dammed['All Pollutants'][3]\n",
    "len(df_dammed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "undammed_pollutant_dict = {}\n",
    "for pol in df_not_dammed['All Pollutants']:\n",
    "    for pollutant in pol:\n",
    "        if pollutant in undammed_pollutant_dict:\n",
    "            undammed_pollutant_dict[pollutant] += 1\n",
    "        else:\n",
    "            undammed_pollutant_dict[pollutant] = 1\n",
    "\n",
    "        \n",
    "            \n",
    "\n",
    "#twentyfive most potent\n",
    "undammed_most_potent = {k:v for (k,v) in undammed_pollutant_dict.items() if v > 28}\n",
    "\n",
    "len(undammed_most_potent)\n",
    "\n",
    "# Agricultural = ['Diazinon', 'Pyrethroids', 'Nitrate', \n",
    "#                 'Chlorpyrifos', 'DDT (Dichlorodiphenyltrichloro ethane)',\n",
    "#                'Dieldrin', 'Nitrogen', 'Total Nitrogen as N']\n",
    "# Metals = ['Copper', 'Zinc', 'Lead', 'Iron']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(undammed_pollutant_dict['Mercury'])\n",
    "print(dammed_pollutant_dict['Mercury'], dammed_pollutant_dict['Unknown Toxicity'])\n",
    "\n",
    "sum = 0\n",
    "for k, v in undammed_pollutant_dict.items():\n",
    "    sum += v\n",
    "16/sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot bars side by side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5\n",
    "men_means = (20, 35, 30, 35, 27)\n",
    "women_means = (25, 32, 34, 20, 25)\n",
    "\n",
    "ind = np.arange(N) \n",
    "width = 0.35       \n",
    "plt.bar(ind, men_means, width, label='Men')\n",
    "plt.bar(ind + width, women_means, width,\n",
    "    label='Women')\n",
    "\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Scores by group and gender')\n",
    "\n",
    "plt.xticks(ind + width / 2, ('G1', 'G2', 'G3', 'G4', 'G5'))\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_list = []\n",
    "for k, v in dammed_most_potent.items():\n",
    "    if k not in x_list:\n",
    "        x_list.append(k)\n",
    "    \n",
    "for k, v in undammed_most_potent.items():\n",
    "    if k not in x_list:\n",
    "        x_list.append(k)\n",
    "x_list = sorted(x_list)\n",
    "\n",
    "dammed = []\n",
    "for item in x_list:\n",
    "    if item in dammed_most_potent:\n",
    "        dammed.append(dammed_most_potent[item])\n",
    "    else:\n",
    "        dammed.append(0.5)\n",
    "undammed = []\n",
    "for item in x_list:\n",
    "    if item in undammed_most_potent:\n",
    "        undammed.append(undammed_most_potent[item])\n",
    "    else:\n",
    "        undammed.append(0.5)\n",
    "        \n",
    "fig, ax = plt.subplots(figsize=(20, 5))\n",
    "        \n",
    "N = len(x_list)\n",
    "ind = np.arange(N)\n",
    "width = 0.4\n",
    "      \n",
    "ax.bar(ind, dammed, width, label='Dammed')\n",
    "ax.bar(ind + width , undammed, width,\n",
    "      label='Undammed')\n",
    "\n",
    "plt.ylabel('# of Occurances of Impairment')\n",
    "plt.title('Top 15 Impairments in Dammed and Undammed Rivers')\n",
    "\n",
    "plt.xticks(ind + width / 2, x_list)\n",
    "plt.setp(plt.gca().get_xticklabels(), rotation=30, horizontalalignment='right')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dammed_most_potent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-1f3584987bee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdammed_most_potent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0md_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdammed_most_potent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dammed_most_potent' is not defined"
     ]
    }
   ],
   "source": [
    "d_keys = dammed_most_potent.keys()\n",
    "d_values = dammed_most_potent.values()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(25,5))\n",
    "plt.bar(d_keys, d_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_keys = undammed_most_potent.keys()\n",
    "u_values = undammed_most_potent.values()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(25,5))\n",
    "plt.bar(u_keys, u_values, color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## let's go through pollutants and classify them as 'direct human addition' or 'change of environmental condition'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum=0\n",
    "for k, v in undammed_most_potent.items():\n",
    "    sum += v\n",
    "    print(k, v)\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying top 15 pollutants as either 'Yes' or 'No' if they are TMDL solvable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatable = {}\n",
    "treatable['Diazinon'] = 'Yes'\n",
    "treatable['Sedimentation/Siltation'] = 'No'\n",
    "treatable['Pathogens'] = 'Yes'\n",
    "treatable['Low Dissolved Oxygen'] = 'No'\n",
    "treatable['Fecal Coliform'] = 'Yes'\n",
    "treatable['Nitrate'] = 'Yes'\n",
    "treatable['Sediment Toxicity'] = 'No'\n",
    "treatable['Unknown Toxicity'] = 'No'\n",
    "treatable['Chlorpyrifos'] = 'Yes'\n",
    "treatable['Escherichia coli (E. coli)'] = 'Yes'\n",
    "treatable['pH'] = 'No'\n",
    "treatable['Chloride'] = 'Yes'\n",
    "treatable['Turbidity'] = 'No'\n",
    "treatable['Pathogens'] = 'No'\n",
    "treatable['Selenium'] = 'Yes'\n",
    "treatable['Temperature'] = 'No'\n",
    "treatable['Mercury'] = 'No'\n",
    "treatable['Copper'] = 'Yes'\n",
    "treatable['Total Dissolved Solids'] = 'No'\n",
    "treatable['Trash'] = 'Yes'\n",
    "treatable['Toxicity'] = 'No'\n",
    "treatable['water'] = 'No'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undammed %solvable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "undammed_solvable = 0\n",
    "undammed_unsolvable = 0\n",
    "for k, v in undammed_most_potent.items():\n",
    "    if he[k] == 'Yes':\n",
    "        undammed_solvable += v\n",
    "    else:\n",
    "        undammed_unsolvable += v\n",
    "print(undammed_solvable, undammed_unsolvable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dammed %unsolvable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solvability(most_potent_dict, he):\n",
    "    sum=0\n",
    "    solvable = 0\n",
    "    unsolvable = 0\n",
    "    for k, v in most_potent_dict.items():\n",
    "        if he[k] == 'Yes':\n",
    "            solvable += v\n",
    "        else:\n",
    "            unsolvable += v\n",
    "        sum += v\n",
    "    return [solvable, unsolvable]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### solvable vs. unsolvable pie chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dammed_vs_natural = [5, 7]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "for s, ax in zip(dammed_vs_natural, axs.flatten()):\n",
    "    ax.axis('equal')\n",
    "    ax.pie(solvability(s, treatable), explode=explode, labels=labels, colors=['steelblue', 'goldenrod'], autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart, where the slices will be ordered and plotted counter-clockwise:\n",
    "labels = ['Solvable with TMDLs', 'Not Feasibly Solved with TMDLs']\n",
    "solvable = solvability(undammed_most_potent, he)\n",
    "explode = (0, 0.1)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n",
    "\n",
    "fig1, ax1 = plt.subplots(figsize=(4.5, 4.5))\n",
    "ax1.pie(solvable, explode=explode, labels=labels, colors=['steelblue', 'goldenrod'], autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "ax1.set_title('TMDL Feasibility for Undammed Rivers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Solvable with TMDLs', 'Not Feasibly Solved with TMDLs']\n",
    "solvable = solvability(dammed_most_potent, he)\n",
    "explode = (0, 0.1)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n",
    "\n",
    "fig1, ax1 = plt.subplots(figsize=(4.5,4.5))\n",
    "ax1.pie(solvable, explode=explode, labels=labels, colors=['steelblue', 'goldenrod'], autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "ax1.set_title('TMDL Feasibility for Dammed Rivers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_d=0\n",
    "for k, v in dammed_most_potent.items():\n",
    "    sum_d += v\n",
    "    print(k, v)\n",
    "print(sum_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "he"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run an A/B test to see whether there is a difference in the makeup of 'TMDL Treatable' vs. 'Environmental' for dammed and undammed!\n",
    "\n",
    "Ho: Both undammed and dammed have same proportion of TMDL treatable to environmental impairements\n",
    "Ha: dammed and undammed have a different proportion of TMDL to Environmental impairments\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
